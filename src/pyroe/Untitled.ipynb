{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cf657d8-a620-40b0-acf9-02e2cc17b2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "import urllib.request \n",
    "import tarfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b497733e-99f5-4c36-b6e2-e2ea815260b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def say(quiet, words):\n",
    "    if not quiet:\n",
    "        print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1c9b839-87e0-4e83-90b3-5b4b71562be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/scratch5/dongze/CODE/python/pyroe/src/pyroe'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d6ebbd2-56d8-47e5-b914-6628e587d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = os.path.join('data', 'available_datasets.tsv')\n",
    "available_datasets = pd.read_csv(my_file, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88a9f6f2-516a-4e9e-b6cd-d8d74e3296fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chemistry</th>\n",
       "      <th>reference</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>link</th>\n",
       "      <th>data_url</th>\n",
       "      <th>MD5</th>\n",
       "      <th>delete_fastq</th>\n",
       "      <th>feature_barcode</th>\n",
       "      <th>library_csv</th>\n",
       "      <th>quant_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v3</td>\n",
       "      <td>human2020A</td>\n",
       "      <td>500 Human PBMCs, 3' LT v3.1, Chromium Controller</td>\n",
       "      <td>https://www.10xgenomics.com/resources/datasets...</td>\n",
       "      <td>https://cf.10xgenomics.com/samples/cell-exp/6....</td>\n",
       "      <td>5f080c6082f11ea9fc6448482e6fb590</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://umd.box.com/shared/static/tg919re5gd4k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v3</td>\n",
       "      <td>human2020A</td>\n",
       "      <td>500 Human PBMCs, 3' LT v3.1, Chromium X</td>\n",
       "      <td>https://www.10xgenomics.com/resources/datasets...</td>\n",
       "      <td>https://cf.10xgenomics.com/samples/cell-exp/6....</td>\n",
       "      <td>5b36a7bfda36a7093adc8e30c3fa92c8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://umd.box.com/shared/static/lrl68q2lz0lt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v3</td>\n",
       "      <td>human2020A</td>\n",
       "      <td>1k PBMCs from a Healthy Donor (v3 chemistry)</td>\n",
       "      <td>https://www.10xgenomics.com/resources/datasets...</td>\n",
       "      <td>https://cf.10xgenomics.com/samples/cell-exp/3....</td>\n",
       "      <td>265ebe8f77ad90db350984d9c7a59e52</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://umd.box.com/shared/static/wrn19wsmkem1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v3</td>\n",
       "      <td>mm10-2020A</td>\n",
       "      <td>10k PBMCs from a Healthy Donor (v3 chemistry)</td>\n",
       "      <td>https://www.10xgenomics.com/resources/datasets...</td>\n",
       "      <td>https://s3-us-west-2.amazonaws.com/10x.files/s...</td>\n",
       "      <td>e0021592e209642d71f5dc420cf4c5c0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://umd.box.com/shared/static/01j9574g1yd9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v3</td>\n",
       "      <td>human2020A</td>\n",
       "      <td>10k Human PBMCs, 3' v3.1, Chromium X</td>\n",
       "      <td>https://www.10xgenomics.com/resources/datasets...</td>\n",
       "      <td>https://s3-us-west-2.amazonaws.com/10x.files/s...</td>\n",
       "      <td>43ea77ed6f860597c568e9ff819f0504</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://umd.box.com/shared/static/jvvzacmo98vx...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chemistry   reference                                      dataset_name  \\\n",
       "0        v3  human2020A  500 Human PBMCs, 3' LT v3.1, Chromium Controller   \n",
       "1        v3  human2020A           500 Human PBMCs, 3' LT v3.1, Chromium X   \n",
       "2        v3  human2020A      1k PBMCs from a Healthy Donor (v3 chemistry)   \n",
       "3        v3  mm10-2020A     10k PBMCs from a Healthy Donor (v3 chemistry)   \n",
       "4        v3  human2020A              10k Human PBMCs, 3' v3.1, Chromium X   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.10xgenomics.com/resources/datasets...   \n",
       "1  https://www.10xgenomics.com/resources/datasets...   \n",
       "2  https://www.10xgenomics.com/resources/datasets...   \n",
       "3  https://www.10xgenomics.com/resources/datasets...   \n",
       "4  https://www.10xgenomics.com/resources/datasets...   \n",
       "\n",
       "                                            data_url  \\\n",
       "0  https://cf.10xgenomics.com/samples/cell-exp/6....   \n",
       "1  https://cf.10xgenomics.com/samples/cell-exp/6....   \n",
       "2  https://cf.10xgenomics.com/samples/cell-exp/3....   \n",
       "3  https://s3-us-west-2.amazonaws.com/10x.files/s...   \n",
       "4  https://s3-us-west-2.amazonaws.com/10x.files/s...   \n",
       "\n",
       "                                MD5  delete_fastq  feature_barcode  \\\n",
       "0  5f080c6082f11ea9fc6448482e6fb590             1              NaN   \n",
       "1  5b36a7bfda36a7093adc8e30c3fa92c8             1              NaN   \n",
       "2  265ebe8f77ad90db350984d9c7a59e52             1              NaN   \n",
       "3  e0021592e209642d71f5dc420cf4c5c0             1              NaN   \n",
       "4  43ea77ed6f860597c568e9ff819f0504             1              NaN   \n",
       "\n",
       "   library_csv                                         quant_link  \n",
       "0          NaN  https://umd.box.com/shared/static/tg919re5gd4k...  \n",
       "1          NaN  https://umd.box.com/shared/static/lrl68q2lz0lt...  \n",
       "2          NaN  https://umd.box.com/shared/static/wrn19wsmkem1...  \n",
       "3          NaN  https://umd.box.com/shared/static/01j9574g1yd9...  \n",
       "4          NaN  https://umd.box.com/shared/static/jvvzacmo98vx...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_datasets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0175c59c-3c31-41eb-9c13-4abe485be26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ids = [1, 3, 2]\n",
    "output_dir = \"processed_data\"\n",
    "quiet = False\n",
    "force = True\n",
    "delete_tar = True\n",
    "nonzero = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "147d7285-08b9-4b72-8c6a-c3c0746a5b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing parameters\n"
     ]
    }
   ],
   "source": [
    "say(quiet, \"Processing parameters\")\n",
    "# load available dataset sheet\n",
    "# location = os.path.dirname(os.path.realpath(__file__))\n",
    "# my_file = os.path.join(location, 'data', 'available_datasets.tsv')\n",
    "my_file = os.path.join('data', 'available_datasets.tsv')\n",
    "available_datasets = pd.read_csv(my_file, sep=\"\\t\")\n",
    "\n",
    "nd = len(dataset_ids)\n",
    "# if no dataset is provided, just return the available dataset dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95147c4a-d264-4be1-aaeb-6dd36f982444",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_format = {\"counts\":[\"U\", \"S\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d3a6616-254d-42c3-83d0-9b3cc5d5361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(list(output_format)) is dict:\n",
    "    # if a dictionary is given,\n",
    "    # it should be either one customized format\n",
    "    # or the format of each fetched datasets\n",
    "    # so check the name \n",
    "    if list(output_format.keys()).sort() != dataset_ids.sort():\n",
    "        # now it should be one customized format\n",
    "        output_format = dict(zip(dataset_ids, [output_format]*nd))\n",
    "    # otherwise, each dataset should get a format, so do nothing\n",
    "elif (type(output_format) is str):\n",
    "    # if a str is given, it should be a pre-defined format\n",
    "    # and it will be used for all datasets\n",
    "    output_format = dict(zip(dataset_ids, [output_format]*nd))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6262431-1ea7-4ddf-aa62-ab7920b17e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib.style import available\n",
    "from pyroe_utils import say\n",
    "\n",
    "def fetch_processed_quant(\n",
    "    dataset_ids = [],\n",
    "    fetch_dir = \"10x_datasets\",\n",
    "    force = False,\n",
    "    delete_tar = True,\n",
    "    quiet = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Download the quantification result of the preprocessed 10x datasets.\n",
    "\n",
    "    Required Parameters\n",
    "    ----------\n",
    "    dataset_ids : `int` or `list`\n",
    "        The list of the id of some available datasets.\n",
    "\n",
    "    Optional Parameters\n",
    "    ----------\n",
    "    fetch_dir : `str` (default: `10x_datasets`)\n",
    "        The path to a directory for storing fetched datasets.\n",
    "    \n",
    "    force : `bool` (default: `False`)\n",
    "        True if existing datasets should be re-downloaded.\n",
    "        \n",
    "    delete_tar : `bool` (default: `True`)\n",
    "        True if intermediate tar files should be deleted.\n",
    "        If False, they will be stored in the datasets_tar\n",
    "        folder under the fetch_dir.\n",
    "        \n",
    "    quiet : `bool` (default: `True`)\n",
    "        True if function should be quiet.\n",
    "        False if messages (including error messages) should be printed out. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    If an empty dataset_ids list is given, a dataframe \n",
    "    containing the information of all available datasets\n",
    "    will be returned. If one or more dataset ids are provided as dataset_ids, \n",
    "    a dictionary of str paths will be returned.   \n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    10x Genomics provides many publicly available single-cell\n",
    "    RNA-sequencing experiments on their \n",
    "    [website](https://www.10xgenomics.com/resources/datasets).\n",
    "    To avoid reinventing wheels, we processed these datasets\n",
    "    using a nextflow-based \n",
    "    [alevin-fry workflow](https://github.com/COMBINE-lab/10x-requant) \n",
    "    and made the quantification results available for free downloading. \n",
    "    Currently, the available datasets include (Notice that dataset id starts form **1**, not zero):\n",
    "    \n",
    "    1. [500 Human PBMCs, 3' LT v3.1, Chromium Controller](https://www.10xgenomics.com/resources/datasets/500-human-pbm-cs-3-lt-v-3-1-chromium-controller-3-1-low-6-1-0): [link to the quant result](https://umd.box.com/shared/static/tg919re5gd4klua39z3zemcg9ya422am.tar)\n",
    "    1. [500 Human PBMCs, 3' LT v3.1, Chromium X](https://www.10xgenomics.com/resources/datasets/500-human-pbm-cs-3-lt-v-3-1-chromium-x-3-1-low-6-1-0): [link to the quant result](https://umd.box.com/shared/static/lrl68q2lz0ltsvs89iazbr302p50wnqj.tar)\n",
    "    1. [1k PBMCs from a Healthy Donor (v3 chemistry)](https://www.10xgenomics.com/resources/datasets/1-k-pbm-cs-from-a-healthy-donor-v-3-chemistry-3-standard-3-0-0): [link to the quant result](https://umd.box.com/shared/static/wrn19wsmkem1jyc9seqpe4pxto5zimwa.tar)\n",
    "    1. [10k PBMCs from a Healthy Donor (v3 chemistry)](https://www.10xgenomics.com/resources/datasets/10-k-pbm-cs-from-a-healthy-donor-v-3-chemistry-3-standard-3-0-0): [link to the quant result](https://umd.box.com/shared/static/01j9574g1yd93noz2pqlqjfrdhx0m1ff.tar)\n",
    "    1. [10k Human PBMCs, 3' v3.1, Chromium X](https://www.10xgenomics.com/resources/datasets/10k-human-pbmcs-3-ht-v3-1-chromium-x-3-1-high): [link to the quant result](https://umd.box.com/shared/static/jvvzacmo98vxfnoimg4dgi52lifhl2aa.tar)\n",
    "    1. [10k Human PBMCs, 3' v3.1, Chromium Controller](https://www.10xgenomics.com/resources/datasets/10k-human-pbmcs-3-v3-1-chromium-controller-3-1-high): [link to the quant result](https://umd.box.com/shared/static/5dzu2tw8nz9tijt8lgmelll6sbaaomh4.tar)\n",
    "    1. [10k Peripheral blood mononuclear cells (PBMCs) from a healthy donor, Single Indexed](https://www.10xgenomics.com/resources/datasets/10-k-peripheral-blood-mononuclear-cells-pbm-cs-from-a-healthy-donor-single-indexed-3-1-standard-4-0-0): [link to the quant result](https://umd.box.com/shared/static/iol9bxiv740xq6m29p2fzcoe8volsi7i.tar)\n",
    "    1. [10k Peripheral blood mononuclear cells (PBMCs) from a healthy donor, Dual Indexed](https://www.10xgenomics.com/resources/datasets/10-k-peripheral-blood-mononuclear-cells-pbm-cs-from-a-healthy-donor-dual-indexed-3-1-standard-4-0-0): [link to the quant result](https://umd.box.com/shared/static/5dzu2tw8nz9tijt8lgmelll6sbaaomh4.tar)\n",
    "    1. [20k Human PBMCs, 3' HT v3.1, Chromium X](https://www.10xgenomics.com/resources/datasets/20-k-human-pbm-cs-3-ht-v-3-1-chromium-x-3-1-high-6-1-0): [link to the quant result](https://umd.box.com/shared/static/c609sk8w6cbn4w0tcwofz4qcyjp67506.tar)\n",
    "    1. [PBMCs from EDTA-Treated Blood Collection Tubes Isolated via SepMate-Ficoll Gradient (3' v3.1 Chemistry)](https://www.10xgenomics.com/resources/datasets/pbmcs-3p_edta_sepmate-3-1-standard): [link to the quant result](https://umd.box.com/shared/static/imedrs558dx4tzxy9uhhxvy0dmjlhjsh.tar)\n",
    "    1. [PBMCs from Heparin-Treated Blood Collection Tubes Isolated via SepMate-Ficoll Gradient (3' v3.1 Chemistry)](https://www.10xgenomics.com/resources/datasets/pbmcs-3p_heparin_sepmate-3-1-standard): [link to the quant result](https://umd.box.com/shared/static/e8gqxali0lwy2nashh5rmmoc6bgj92xm.tar)\n",
    "    1. [PBMCs from ACD-A Treated Blood Collection Tubes Isolated via SepMate-Ficoll Gradient (3' v3.1 Chemistry)](https://www.10xgenomics.com/resources/datasets/pbmcs-3p_acda_sepmate-3-1-standard): [link to the quant result](https://umd.box.com/shared/static/w1kdz3vifqi4ixtqkuwqgc2mpkkiehky.tar)\n",
    "    1. [PBMCs from Citrate-Treated Blood Collection Tubes Isolated via SepMate-Ficoll Gradient (3' v3.1 Chemistry)](https://www.10xgenomics.com/resources/datasets/pbmcs-3p_citrate_sepmate-3-1-standard): [link to the quant result](https://umd.box.com/shared/static/cs0s6e2u0j7d8uc36xsdo6922c7dle6y.tar)\n",
    "    1. [PBMCs from Citrate-Treated Cell Preparation Tubes (3' v3.1 Chemistry)](https://www.10xgenomics.com/resources/datasets/pbmcs-3p_citrate_cpt-3-1-standard): [link to the quant result](https://umd.box.com/shared/static/2tqrzreghvi6nxe94oob1ei1vi4458br.tar)\n",
    "    1. [PBMCs from a Healthy Donor: Whole Transcriptome Analysis](https://www.10xgenomics.com/resources/datasets/pbm-cs-from-a-healthy-donor-whole-transcriptome-analysis-3-1-standard-4-0-0): [link to the quant result](https://umd.box.com/shared/static/dk0hmj5mpqjq56afkr5jibavy9e3yil8.tar)\n",
    "    1. [Whole Blood RBC Lysis for PBMCs and Neutrophils, Granulocytes, 3'](https://www.10xgenomics.com/resources/datasets/whole-blood-rbc-lysis-for-pbmcs-neutrophils-granulocytes-3-3-1-standard): [link to the quant result](https://umd.box.com/shared/static/0gnwx7d9hbdmptyi0ddz6mfa79d1l8be.tar)\n",
    "    1. [Peripheral blood mononuclear cells (PBMCs) from a healthy donor - Manual (channel 5)](https://www.10xgenomics.com/resources/datasets/peripheral-blood-mononuclear-cells-pbm-cs-from-a-healthy-donor-manual-channel-5-3-1-standard-3-1-0): [link to the quant result](https://umd.box.com/shared/static/tn884ctombnj214abt8rp77p7kih5i02.tar)\n",
    "    1. [Peripheral blood mononuclear cells (PBMCs) from a healthy donor - Manual (channel 1)](https://www.10xgenomics.com/resources/datasets/peripheral-blood-mononuclear-cells-pbm-cs-from-a-healthy-donor-manual-channel-1-3-1-standard-3-1-0): [link to the quant result](https://umd.box.com/shared/static/0jcgdgy8woj30oarkwhybk8fly7gb7v8.tar)\n",
    "    1. [Peripheral blood mononuclear cells (PBMCs) from a healthy donor - Chromium Connect (channel 5)](https://www.10xgenomics.com/resources/datasets/peripheral-blood-mononuclear-cells-pbm-cs-from-a-healthy-donor-chromium-connect-channel-5-3-1-standard-3-1-0): [link to the quant result](https://umd.box.com/shared/static/kybks0ncf609xhcwvhv7z743zrmvlg94.tar)\n",
    "    1. [Peripheral blood mononuclear cells (PBMCs) from a healthy donor - Chromium Connect (channel 1)](https://www.10xgenomics.com/resources/datasets/peripheral-blood-mononuclear-cells-pbm-cs-from-a-healthy-donor-chromium-connect-channel-1-3-1-standard-3-1-0): [link to the quant result](https://umd.box.com/shared/static/vtuexhbqiyvfob7qdpvsxl1nbqlo074f.tar)\n",
    "    1. [Hodgkin's Lymphoma, Dissociated Tumor: Whole Transcriptome Analysis](https://www.10xgenomics.com/resources/datasets/hodgkins-lymphoma-dissociated-tumor-whole-transcriptome-analysis-3-1-standard-4-0-0): [link to the quant result](https://umd.box.com/shared/static/qis4ovf34wvq12n2uabdiem6w355qry7.tar)\n",
    "    1. [200 Sorted Cells from Human Glioblastoma Multiforme, 3’ LT v3.1](https://www.10xgenomics.com/resources/datasets/200-sorted-cells-from-human-glioblastoma-multiforme-3-lt-v-3-1-3-1-low-6-0-0): [link to the quant result](https://umd.box.com/shared/static/2xf9xf8m1n5vbvmpo1vshwigs7f7o5jd.tar)\n",
    "    1. [750 Sorted Cells from Human Invasive Ductal Carcinoma, 3’ LT v3.1](https://www.10xgenomics.com/resources/datasets/750-sorted-cells-from-human-invasive-ductal-carcinoma-3-lt-v-3-1-3-1-low-6-0-0): [link to the quant result](https://umd.box.com/shared/static/3txnreehxoj2plyypfs6fkibnnbo72h4.tar)\n",
    "    1. [2k Sorted Cells from Human Glioblastoma Multiforme, 3’ v3.1](https://www.10xgenomics.com/resources/datasets/2-k-sorted-cells-from-human-glioblastoma-multiforme-3-v-3-1-3-1-standard-6-0-0): [link to the quant result](https://umd.box.com/shared/static/n0vpgbdwbnnqdw1h9of2ykk7ive9p6pt.tar)\n",
    "    1. [7.5k Sorted Cells from Human Invasive Ductal Carcinoma, 3’ v3.1](https://www.10xgenomics.com/resources/datasets/7-5-k-sorted-cells-from-human-invasive-ductal-carcinoma-3-v-3-1-3-1-standard-6-0-0): [link to the quant result](https://umd.box.com/shared/static/aly78r6bppqf01npbqfopc3epmp17weu.tar)\n",
    "    1. [Human Glioblastoma Multiforme: 3’v3 Whole Transcriptome Analysis](https://www.10xgenomics.com/resources/datasets/human-glioblastoma-multiforme-3-v-3-whole-transcriptome-analysis-3-standard-4-0-0): [link to the quant result](https://umd.box.com/shared/static/suf8pt3avv4rchxfw0bqrshslzieygef.tar)\n",
    "    1. [1k Brain Cells from an E18 Mouse (v3 chemistry)](https://www.10xgenomics.com/resources/datasets/1-k-brain-cells-from-an-e-18-mouse-v-3-chemistry-3-standard-3-0-0): [link to the quant result](https://umd.box.com/shared/static/4w5eiq3qafbru5ocler39j5j28bvgz98.tar)\n",
    "    1. [10k Brain Cells from an E18 Mouse (v3 chemistry)](https://www.10xgenomics.com/resources/datasets/10-k-brain-cells-from-an-e-18-mouse-v-3-chemistry-3-standard-3-0-0): [link to the quant result](https://umd.box.com/shared/static/tym9m73frtp13vo15jhit9uwuk3mtfdq.tar)\n",
    "    1. [1k Heart Cells from an E18 mouse (v3 chemistry)](https://www.10xgenomics.com/resources/datasets/1-k-heart-cells-from-an-e-18-mouse-v-3-chemistry-3-standard-3-0-0): [link to the quant result](https://umd.box.com/shared/static/d838oy3udjvtzjo7tsdiao7u6sazabeg.tar)\n",
    "    1. [10k Heart Cells from an E18 mouse (v3 chemistry)](https://www.10xgenomics.com/resources/datasets/10-k-heart-cells-from-an-e-18-mouse-v-3-chemistry-3-standard-3-0-0): [link to the quant result](https://umd.box.com/shared/static/efinlf6p8weich13kv3bzrlndsx963v4.tar)\n",
    "    1. [10k Mouse E18 Combined Cortex, Hippocampus and Subventricular Zone Cells, Single Indexed](https://www.10xgenomics.com/resources/datasets/10-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-cells-single-indexed-3-1-standard-4-0-0): [link to the quant result](https://umd.box.com/shared/static/mr0yolo83rjdcdqgu6om4q133fpime8r.tar)\n",
    "    1. [10k Mouse E18 Combined Cortex, Hippocampus and Subventricular Zone Cells, Dual Indexed](https://www.10xgenomics.com/resources/datasets/10-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-cells-dual-indexed-3-1-standard-4-0-0): [link to the quant result](https://umd.box.com/shared/static/mr7raea3v5ccn4dchemwhcimpz7t1cwl.tar)\n",
    "    1. [1k PBMCs from a Healthy Donor (v2 chemistry)](https://www.10xgenomics.com/resources/datasets/1-k-pbm-cs-from-a-healthy-donor-v-2-chemistry-3-standard-3-0-0): [link to the quant result](https://umd.box.com/shared/static/xeya5zr0t0wg0t8c20zu0pdhclxywx3c.tar)\n",
    "    1. [1k Brain Cells from an E18 Mouse (v2 chemistry)](https://www.10xgenomics.com/resources/datasets/1-k-brain-cells-from-an-e-18-mouse-v-2-chemistry-3-standard-3-0-0): [link to the quant result](https://umd.box.com/shared/static/a53twm69uo2xf6778asuvw2aft7wkur5.tar)\n",
    "    1. [1k Heart Cells from an E18 mouse (v2 chemistry)](https://www.10xgenomics.com/resources/datasets/1-k-heart-cells-from-an-e-18-mouse-v-2-chemistry-3-standard-3-0-0): [link to the quant result](https://umd.box.com/shared/static/p4ieuzimfgrjfsr9rzhrn48kved4ha7m.tar)\n",
    "\n",
    "    To obtain the information of the available datasets as \n",
    "    a dataframe, one can run `preprocessed_10x_data()`\n",
    "    \"\"\"\n",
    "    \n",
    "    import pandas as pd\n",
    "    import os\n",
    "    import shutil\n",
    "    import urllib.request \n",
    "    import tarfile\n",
    "\n",
    "    # load available dataset sheet\n",
    "    # location = os.path.dirname(os.path.realpath(__file__))\n",
    "    # my_file = os.path.join(location, 'data', 'available_datasets.tsv')\n",
    "    my_file = os.path.join('data', 'available_datasets.tsv')\n",
    "    available_datasets = pd.read_csv(my_file, sep=\"\\t\")\n",
    "\n",
    "    # if no dataset is provided, just return the available dataset dataframe\n",
    "    if len(dataset_ids) == 0:\n",
    "        return available_datasets\n",
    "\n",
    "    # check the validity of dataset_ids\n",
    "    n_ds = available_datasets.shape[0]\n",
    "    invalid_ids = []\n",
    "    for idx, dataset_id in enumerate(dataset_ids):\n",
    "        if (type(dataset_id) == int):\n",
    "            if dataset_id > n_ds & dataset_id < 1:\n",
    "                print(f\"Found invalid dataset id '{dataset_id}', ignored.\")\n",
    "                invalid_ids.append(idx)\n",
    "        else:\n",
    "            print(f\"Found invalid dataset id '{dataset_id}', ignored.\")\n",
    "            invalid_ids.append(idx)\n",
    "    for i in reversed(invalid_ids):\n",
    "        del dataset_ids[i]\n",
    "\n",
    "    # if no id left, return an error\n",
    "    if not dataset_ids:\n",
    "        raise ValueError(f\"No valid dataset id found, can not proceed\")\n",
    "\n",
    "    # download the quantification tar file for each queried dataset.\n",
    "    quant_dir_list = []\n",
    "    # folder for (temporarily) storing tar files.\n",
    "    tar_dir = os.path.join(fetch_dir, \"datasets_tar\")\n",
    "    if not os.path.exists(tar_dir):\n",
    "        os.makedirs(tar_dir)\n",
    "    \n",
    "    # download the quantification tar file for each queried dataset.\n",
    "    for dataset_id in dataset_ids:\n",
    "        say(quiet, f\"Processing dataset #{dataset_id}\")\n",
    "        dataset_id -= 1\n",
    "        quant_parent_dir = os.path.join(fetch_dir, \n",
    "                                        available_datasets.iloc[dataset_id,5])\n",
    "        tar_file = os.path.join(tar_dir,\n",
    "                            \"\".join([available_datasets.iloc[dataset_id,5], \".tar\"])\n",
    "                                )\n",
    "        if os.path.exists(quant_parent_dir):\n",
    "            say(quiet, f\"  - output dir exists:\\n    {quant_parent_dir}\")\n",
    "            \n",
    "            if force:\n",
    "                say(quiet, \"  - force re-processing\")\n",
    "                shutil.rmtree(quant_parent_dir)\n",
    "            else:\n",
    "                say(quiet, \"  - use the existing quant result\")\n",
    "                quant_dir_list.append(os.path.join(quant_parent_dir, next(os.walk(quant_parent_dir))[1][0]))\n",
    "\n",
    "                continue\n",
    "        say(quiet, \"  - Downloading quant result\")\n",
    "        url = available_datasets.iloc[dataset_id, 9]\n",
    "        urllib.request.urlretrieve(url, tar_file)\n",
    "        # decompress the downloaded tar files\n",
    "        say(quiet, \"  - Decompressing quant result\")\n",
    "        tf = tarfile.open(tar_file)\n",
    "        tf.extractall(quant_parent_dir)\n",
    "        quant_dir_list.append(os.path.join(quant_parent_dir, next(os.walk(quant_parent_dir))[1][0]))\n",
    "    \n",
    "    # delete tar if needed\n",
    "    if delete_tar:\n",
    "        say(quiet, \"Removing downloaded tar files\")\n",
    "    shutil.rmtree(tar_dir)\n",
    "\n",
    "    say(quiet, \"Done\")\n",
    "    return dict(zip(dataset_ids, quant_dir_list))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8ac7c81-f7e2-4a19-851e-812be2d9c266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset #1\n",
      "  - output dir exists:\n",
      "    10x_datasets/5f080c6082f11ea9fc6448482e6fb590\n",
      "  - use the existing quant result\n",
      "Processing dataset #2\n",
      "  - output dir exists:\n",
      "    10x_datasets/5b36a7bfda36a7093adc8e30c3fa92c8\n",
      "  - use the existing quant result\n",
      "Processing dataset #3\n",
      "  - output dir exists:\n",
      "    10x_datasets/265ebe8f77ad90db350984d9c7a59e52\n",
      "  - use the existing quant result\n",
      "Removing downloaded tar files\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: '10x_datasets/5f080c6082f11ea9fc6448482e6fb590/5f080c6082f11ea9fc6448482e6fb590_fry_unfilt_quant_usa_cr-like',\n",
       " 2: '10x_datasets/5b36a7bfda36a7093adc8e30c3fa92c8/5b36a7bfda36a7093adc8e30c3fa92c8_fry_unfilt_quant_usa_cr-like',\n",
       " 3: '10x_datasets/265ebe8f77ad90db350984d9c7a59e52/265ebe8f77ad90db350984d9c7a59e52_fry_unfilt_quant_usa_cr-like'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_processed_quant([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0017472-8bd5-4cd2-b662-16d0b2a52fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import scanpy\n",
    "except ModuleNotFoundError as e:\n",
    "    print(\"scanpy must be installed to enable the load_fry() function. Use `conda install -c scanpy ` or `pip install scanpy` to install it.\")\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "import scanpy\n",
    "\n",
    "def load_fry(frydir, output_format=\"scRNA\", nonzero = False, quiet=False):\n",
    "    \"\"\"\n",
    "    load alevin-fry quantification result into an AnnData object\n",
    "    \n",
    "    Required Parameters\n",
    "    ----------\n",
    "    frydir : `str`\n",
    "        The path to a output directory returned by alevin-fry quant command. \\\\\n",
    "        The directory containing the alevin-fry quantification (i.e. the the quant.json file & alevin subdirectory).\n",
    "    \n",
    "    Optional Parameters\n",
    "    ----------\n",
    "    output_format : `str` or `dict`\n",
    "        A string represents one of the pre-defined output formats, which are \"scRNA\", \"snRNA\" and \"velocity\". \\\\\n",
    "        If a customized format of the returned `AnnData` is needed, one can pass a Dictionary.\\\\\n",
    "        See Notes section for details.\n",
    "\n",
    "    nonzero : `bool` (default: `False`)\n",
    "        True if cells with non-zero expression value across all genes should be filtered in each layer.\n",
    "        False if unexpressed genes should be kept.\n",
    "\n",
    "    quiet : `bool` (default: `False`)\n",
    "        True if function should be quiet.\n",
    "        False if messages (including error messages) should be printed out. \n",
    "\n",
    "    Notes\n",
    "    ----------\n",
    "    The `output_format` argument takes either a dictionary that defines the customized format or \n",
    "    a string that represents one of the pre-defined format of the returned `AnnData` object.\n",
    "\n",
    "    Each of the pre-defined formats contains a `X` field and some optional extra `AnnData.layers` \n",
    "    obtained from the submatrices representing unspliced (U), spliced (S) and ambiguous (A) counts \n",
    "    returned by alevin-fry. \n",
    "    \n",
    "    The following formats are defined:\n",
    "\n",
    "    * \"scRNA\": \\\\\n",
    "        This format is recommended for single cell RNA-sequencing experiments. \n",
    "        It returns a `X` field that contains the S+A count of each gene in each cell without any extra layers.\n",
    "\n",
    "    * \"snRNA\": \\\\\n",
    "        This format is recommended for single nucleus RNA-sequencing experiments. \n",
    "        It returns a `X` field that contains the U+S+A count of each gene in each cell without any extra layers.\n",
    "\n",
    "    * \"raw\": \\\\\n",
    "        This format uses the S count matrix as the `X` field and put the U, S, and A counts into three \n",
    "        separate layers, which are \"unspliced\", \"spliced\" and \"ambiguous\".\n",
    "\n",
    "    * \"velocity\": \\\\\n",
    "        This format is the same as \"scRNA\", except it contains two extra layers: the \"spliced\" layer, \n",
    "        which contains the S+A counts, and the \"unspliced\" layer, which contains the U counts.\n",
    "\n",
    "    A custom output format can be defined using a Dictionary specifying the desired format of the output `Anndata` object.  \n",
    "    If the input is not a USA mode quantification directory, this parameter is ignored\n",
    "    and the count matrix is returned in the `X` field of the returned `AnnData` object.  If the input\n",
    "    quantification directory contains a USA mode quantification, then there are 3 sub-matrices that can \n",
    "    be referenced in the dictionary; 'U', 'S', 'A' containing, respectively, unspliced, spliced and \n",
    "    ambiguous counts.  The dictionary should have entries of the form `key` (str) : `value` (list[str]).\n",
    "    The following constraints apply : there should be one key-value pair with the key `X`, the resulting\n",
    "    counts will be returned in the `X` field of the AnnData object. There can be an arbitrary number\n",
    "    of other key-value pairs, but each will be returned as a layer of the resulting AnnData object.\n",
    "    Within the key-value pairs, the key refers to the layer name that will be given to the combined \n",
    "    count matrix upon output, and the value should be a subset of `['U', 'S', 'A']` that defines \n",
    "    which sub-matrices should be summed.  For example:\n",
    "    `{'X' : ['S', 'A'], 'unspliced' : ['U']}`\n",
    "    will result in a return AnnData object where the X field has a matrix in which each entry \n",
    "    corresponds to the summed spliced and ambiguous counts for each gene in each cell, and there\n",
    "    is an additional \"unspliced\" layer, whose counts are taken directly from the unspliced sub-matrix.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "        An AnnData object with X and layers corresponding to the requested `output_format`.\n",
    "        \n",
    "    \"\"\"\n",
    "    import json\n",
    "    import os\n",
    "    import pandas as pd\n",
    "\n",
    "    # since alevin-fry 0.4.1 the generic \"meta_info.json\"\n",
    "    # has been replaced by a more informative name for each\n",
    "    # sub-command. For quantification, it is \"quant.json\".\n",
    "    # we check for both files here, in order.\n",
    "    meta_info_files = [\"quant.json\", \"meta_info.json\"]\n",
    "\n",
    "    fpath = os.path.sep.join([frydir, meta_info_files[0]])\n",
    "    # first, check for the new file, if we don't find it, check\n",
    "    # for the old one.\n",
    "    if not os.path.exists(fpath):\n",
    "        if quiet:\n",
    "            print(f\"Did not find a {meta_info_files[0]} file, checking for older {meta_info_files[1]}.\")\n",
    "        fpath = os.path.sep.join([frydir, meta_info_files[1]])\n",
    "        # if we don't find the old one either, then return None\n",
    "        if not os.path.exists(fpath):\n",
    "            raise IOError(f\"Found no {meta_info_files[1]} file either; cannot proceed.\")\n",
    "\n",
    "    # if we got here then we had a valid json file, so \n",
    "    # use it to get the number of genes, and if we are \n",
    "    # in USA mode or not.\n",
    "    meta_info = json.load(open(fpath))\n",
    "    ng = meta_info['num_genes']\n",
    "    usa_mode = meta_info['usa_mode']\n",
    "    if quiet:\n",
    "        print(f\"USA mode: {usa_mode}\")\n",
    "\n",
    "    # if we are in USA mode\n",
    "    if usa_mode:\n",
    "        # preparation\n",
    "        # each gene has 3 splicing statuses, so the actual number of distinct \n",
    "        # genes is ng/3.\n",
    "        ng = int(ng/3)\n",
    "        output_assays = process_output_format(output_format, quiet)\n",
    "    elif quiet:\n",
    "        print(\"Processing input in standard mode, the count matrix will be stored in field 'X'.\")\n",
    "        if output_format != \"scRNA\":\n",
    "            print(\"Output_format will be ignored.\")\n",
    "\n",
    "    # read the actual input matrix\n",
    "    af_raw = scanpy.read_mtx(os.path.sep.join([frydir, \"alevin\", \"quants_mat.mtx\"]))\n",
    "    afg = [ l.rstrip() for l in open(os.path.sep.join([frydir, \"alevin\", \"quants_mat_cols.txt\"])).readlines()][:ng]\n",
    "    # read the gene ids\n",
    "    afg_df =  pd.DataFrame(afg, columns=[\"gene_ids\"])\n",
    "    afg_df = afg_df.set_index(\"gene_ids\")\n",
    "    # and the barcodes\n",
    "    abc = [ l.rstrip() for l in open(os.path.sep.join([frydir, \"alevin\", \"quants_mat_rows.txt\"])).readlines() ]\n",
    "    abc_df = pd.DataFrame(abc, columns=[\"barcodes\"])\n",
    "    abc_df.index = abc_df[\"barcodes\"]\n",
    "    \n",
    "    x = af_raw.X\n",
    "    # if we're not in USA mode, just combine this info into \n",
    "    # an AnnData object\n",
    "    if not usa_mode:\n",
    "        af = scanpy.AnnData(x.T, var=abc_df, obs=afg_df)\n",
    "        af = af.T\n",
    "        \n",
    "    else: # USA mode\n",
    "        # otherwise, combine the sub-matrices into the output object as \n",
    "        # specified by `output_assays`\n",
    "        rd = {'S' : range(0,ng), 'U' : range(ng, 2*ng), 'A' : range(2*ng,3*ng)}\n",
    "        xcounts = output_assays['X']\n",
    "        o = x[:, rd[xcounts[0]]]\n",
    "        for wc in xcounts[1:]:\n",
    "            o += x[:, rd[wc]]\n",
    "        af = scanpy.AnnData(o.T, var=abc_df, obs=afg_df)\n",
    "        af = af.T\n",
    "\n",
    "        # now, if there are other layers requested, populate those\n",
    "        for other_layer in output_assays.keys() - 'X':\n",
    "            xcounts = output_assays[other_layer]\n",
    "            o = x[:, rd[xcounts[0]]]\n",
    "            for wc in xcounts[1:]:\n",
    "                o += x[:, rd[wc]] \n",
    "            af.layers[other_layer] = o\n",
    "    \n",
    "    if nonzero:\n",
    "        import numpy as np\n",
    "\n",
    "        not_zero_genes = af.X.sum(axis=0).A1 > 0\n",
    "        if usa_mode:\n",
    "            for other_layer in output_assays.keys() - 'X':\n",
    "                not_zero_genes = np.logical_or(not_zero_genes, af.layers[other_layer].sum(axis=0).A1 > 0)\n",
    "\n",
    "        af = af[:, not_zero_genes]\n",
    "\n",
    "        if quiet:\n",
    "            print(f\"Filtered {np.sum(~not_zero_genes)} non-expressed genes.\")\n",
    "    \n",
    "    return af\n",
    "\n",
    "def process_output_format(output_format, quiet):\n",
    "    # make sure output_format isn't empty\n",
    "    if not output_format:\n",
    "        raise ValueError(\"output_format cannot be empty\")  \n",
    "\n",
    "    if isinstance(output_format, (str, dict)):\n",
    "        if isinstance(output_format, str):\n",
    "            predefined_format = {'scrna': {\"X\": [\"S\", \"A\"]}, \n",
    "                \"snrna\": {\"X\": [\"U\", \"S\", \"A\"]},\n",
    "                \"velocity\": {\"X\" : [\"S\", \"A\"], \"spliced\": [\"S\", \"A\"], \"unspliced\": [\"U\"]},\n",
    "                \"raw\": {\"X\" : [\"S\"], \"spliced\": [\"S\"], \"unspliced\": [\"U\"],  \"ambiguous\": [\"A\"]}\n",
    "            }\n",
    "\n",
    "            output_format = output_format.lower()\n",
    "            if output_format not in predefined_format.keys():\n",
    "                # invalid output_format string\n",
    "                if quiet:\n",
    "                    print(\"Provided output_format string must be 'scRNA', 'snRNA', 'raw' or 'velocity'.\")\n",
    "                    print(\"See function help message for details.\")\n",
    "                raise ValueError(\"Invalid output_format.\")\n",
    "            if quiet:\n",
    "                print(\"Using pre-defined output format:\", output_format)\n",
    "                print(f\"Will populate output field X with sum of counts frorm {predefined_format[output_format]['X']}.\")\n",
    "                for (k,v) in predefined_format[output_format].items():\n",
    "                    if k != 'X':\n",
    "                        print(f'Will combine {v} into output layer {k}.') \n",
    "\n",
    "            return predefined_format[output_format]\n",
    "        else:\n",
    "            if quiet:\n",
    "                print(\"Processing user-defined output format.\")\n",
    "            # make sure the X is there\n",
    "            if 'X' not in output_format.keys():\n",
    "                raise ValueError('In USA mode some sub-matrices must be assigned to the \\\"X\\\" (default) output.')\n",
    "            print(f\"Will populate output field X with sum of counts frorm {output_format['X']}.\")\n",
    "\n",
    "            valid_counts = [\"U\", \"S\", \"A\"]\n",
    "            for (k,v) in output_format.items():\n",
    "                if not v:\n",
    "                    # empty list\n",
    "                    raise ValueError(f\"The element list of key '{k}' in output_format is empty. Please remove it.\")\n",
    "                \n",
    "                # v contains Non-USA element\n",
    "                if len(set(v) - set(['U', 'S', 'A'])) != 0:\n",
    "                    # invalid value\n",
    "                    raise ValueError(f\"Found non-USA element in output_format element list '{v}' for key '{k}'; cannot proceed.\")\n",
    "                if quiet and (k != 'X'):\n",
    "                    print(f'Will combine {v} into output layer {k}.') \n",
    "\n",
    "            return output_format\n",
    "    else:\n",
    "        raise ValueError(\"Provided invalid output_format. See function help message for details\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc766443-6484-4435-a4bc-7a5cfdfb1a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyroe_utils import say\n",
    "# from fetch_processed_quant import fetch_processed_quant\n",
    "# from load_fry import load_fry\n",
    "\n",
    "\n",
    "def load_processed_quant(\n",
    "    dataset_ids = [],\n",
    "    fetch_dir = \"10x_datasets\",\n",
    "    force = False,\n",
    "    delete_tar = True,\n",
    "    output_format=\"scRNA\",\n",
    "    nonzero = False,\n",
    "    quiet = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Download the quantification result of the preprocessed 10x datasets.\n",
    "\n",
    "    Required Parameters\n",
    "    ----------\n",
    "    dataset_ids : `int` or `list`\n",
    "        The list of the id of some available datasets.\n",
    "\n",
    "    Optional Parameters\n",
    "    ----------\n",
    "    fetch_dir : `str` (default: `10x_datasets`)\n",
    "        The path to a directory for storing downloaded datasets.\n",
    "\n",
    "    force : `bool` (default: `False`)\n",
    "        True if existing datasets should be re-downloaded.\n",
    "        \n",
    "    delete_tar : `bool` (default: `True`)\n",
    "        True if intermediate tar files should be deleted.\n",
    "        If False, they will be stored in the datasets_tar\n",
    "        folder under the fetch_dir.\n",
    "    \n",
    "    output_format : `str` or `dict`\n",
    "        Either a str represents one of the pre-defined output \n",
    "        formats, which are \"scRNA\", \"snRNA\" and \"velocity\", \n",
    "        that will be used for loading all fetched datasets, \\\\\n",
    "        or a `dict` represent a customized format that will\n",
    "        be used for loading all fetched datasets,\\\\\n",
    "        or a `dict` of `str` or `dict` which keys are the dataset\n",
    "        ids to be fetched and values are the output_format that will \n",
    "        be used for loading each fetched dataset. \n",
    "        See [load_fry](https://github.com/COMBINE-lab/pyroe/blob/main/src/pyroe/load_fry.py) \n",
    "        for the details of output_format.\n",
    "\n",
    "    nonzero : `bool` or `list` (default: `False`)\n",
    "        True if cells with non-zero expression value \n",
    "        across all genes should be filtered in each layer.\n",
    "        False if unexpressed genes should be kept.\n",
    "        If a list of `bool` is passed, the booleans\n",
    "        will be used for loading each fetched dataset in order.\n",
    "\n",
    "    quiet : `bool` (default: `False`)\n",
    "        True if function should be quiet.\n",
    "        False if messages (including error messages) should be printed out. \n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    If an empty dataset_ids list is given, a data frame \n",
    "    containing the information of all available datasets\n",
    "    will be returned. If an dataset id is provided as dataset_ids, \n",
    "    a str represents path to the downloaded dataset will be \n",
    "    returned. If a list of dataset ids is provided as dataset_ids, \n",
    "    a dictionary of AnnData objects will be returned. The keys\n",
    "    are the dataset ids, the values are the corresponding AnnData objects.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    10x Genomics provides many publicly available single-cell\n",
    "    RNA-sequencing experiments on their \n",
    "    [website](https://www.10xgenomics.com/resources/datasets).\n",
    "    To avoid reinventing wheels, we processed these datasets\n",
    "    using a nextflow-based \n",
    "    [alevin-fry workflow](https://github.com/COMBINE-lab/10x-requant) \n",
    "    and made the quantification results available for free downloading. \n",
    "    Currently, the available datasets include (Notice that dataset id starts form **1**, not zero):\n",
    "    \n",
    "    1. [500 Human PBMCs, 3' LT v3.1, Chromium Controller](https://www.10xgenomics.com/resources/datasets/500-human-pbm-cs-3-lt-v-3-1-chromium-controller-3-1-low-6-1-0): [link to the quant result](https://umd.box.com/shared/static/tg919re5gd4klua39z3zemcg9ya422am.tar)\n",
    "    1. [500 Human PBMCs, 3' LT v3.1, Chromium X](https://www.10xgenomics.com/resources/datasets/500-human-pbm-cs-3-lt-v-3-1-chromium-x-3-1-low-6-1-0): [link to the quant result](https://umd.box.com/shared/static/lrl68q2lz0ltsvs89iazbr302p50wnqj.tar)\n",
    "    1. [1k PBMCs from a Healthy Donor (v3 chemistry)](https://www.10xgenomics.com/resources/datasets/1-k-pbm-cs-from-a-healthy-donor-v-3-chemistry-3-standard-3-0-0): [link to the quant result](https://umd.box.com/shared/static/wrn19wsmkem1jyc9seqpe4pxto5zimwa.tar)\n",
    "    1. [10k PBMCs from a Healthy Donor (v3 chemistry)](https://www.10xgenomics.com/resources/datasets/10-k-pbm-cs-from-a-healthy-donor-v-3-chemistry-3-standard-3-0-0): [link to the quant result](https://umd.box.com/shared/static/01j9574g1yd93noz2pqlqjfrdhx0m1ff.tar)\n",
    "    1. [10k Human PBMCs, 3' v3.1, Chromium X](https://www.10xgenomics.com/resources/datasets/10k-human-pbmcs-3-ht-v3-1-chromium-x-3-1-high): [link to the quant result](https://umd.box.com/shared/static/jvvzacmo98vxfnoimg4dgi52lifhl2aa.tar)\n",
    "    1. [10k Human PBMCs, 3' v3.1, Chromium Controller](https://www.10xgenomics.com/resources/datasets/10k-human-pbmcs-3-v3-1-chromium-controller-3-1-high): [link to the quant result](https://umd.box.com/shared/static/5dzu2tw8nz9tijt8lgmelll6sbaaomh4.tar)\n",
    "    1. [10k Peripheral blood mononuclear cells (PBMCs) from a healthy donor, Single Indexed](https://www.10xgenomics.com/resources/datasets/10-k-peripheral-blood-mononuclear-cells-pbm-cs-from-a-healthy-donor-single-indexed-3-1-standard-4-0-0): [link to the quant result](https://umd.box.com/shared/static/iol9bxiv740xq6m29p2fzcoe8volsi7i.tar)\n",
    "    1. [10k Peripheral blood mononuclear cells (PBMCs) from a healthy donor, Dual Indexed](https://www.10xgenomics.com/resources/datasets/10-k-peripheral-blood-mononuclear-cells-pbm-cs-from-a-healthy-donor-dual-indexed-3-1-standard-4-0-0): [link to the quant result](https://umd.box.com/shared/static/5dzu2tw8nz9tijt8lgmelll6sbaaomh4.tar)\n",
    "    1. [20k Human PBMCs, 3' HT v3.1, Chromium X](https://www.10xgenomics.com/resources/datasets/20-k-human-pbm-cs-3-ht-v-3-1-chromium-x-3-1-high-6-1-0): [link to the quant result](https://umd.box.com/shared/static/c609sk8w6cbn4w0tcwofz4qcyjp67506.tar)\n",
    "    1. [PBMCs from EDTA-Treated Blood Collection Tubes Isolated via SepMate-Ficoll Gradient (3' v3.1 Chemistry)](https://www.10xgenomics.com/resources/datasets/pbmcs-3p_edta_sepmate-3-1-standard): [link to the quant result](https://umd.box.com/shared/static/imedrs558dx4tzxy9uhhxvy0dmjlhjsh.tar)\n",
    "    1. [PBMCs from Heparin-Treated Blood Collection Tubes Isolated via SepMate-Ficoll Gradient (3' v3.1 Chemistry)](https://www.10xgenomics.com/resources/datasets/pbmcs-3p_heparin_sepmate-3-1-standard): [link to the quant result](https://umd.box.com/shared/static/e8gqxali0lwy2nashh5rmmoc6bgj92xm.tar)\n",
    "    1. [PBMCs from ACD-A Treated Blood Collection Tubes Isolated via SepMate-Ficoll Gradient (3' v3.1 Chemistry)](https://www.10xgenomics.com/resources/datasets/pbmcs-3p_acda_sepmate-3-1-standard): [link to the quant result](https://umd.box.com/shared/static/w1kdz3vifqi4ixtqkuwqgc2mpkkiehky.tar)\n",
    "    1. [PBMCs from Citrate-Treated Blood Collection Tubes Isolated via SepMate-Ficoll Gradient (3' v3.1 Chemistry)](https://www.10xgenomics.com/resources/datasets/pbmcs-3p_citrate_sepmate-3-1-standard): [link to the quant result](https://umd.box.com/shared/static/cs0s6e2u0j7d8uc36xsdo6922c7dle6y.tar)\n",
    "    1. [PBMCs from Citrate-Treated Cell Preparation Tubes (3' v3.1 Chemistry)](https://www.10xgenomics.com/resources/datasets/pbmcs-3p_citrate_cpt-3-1-standard): [link to the quant result](https://umd.box.com/shared/static/2tqrzreghvi6nxe94oob1ei1vi4458br.tar)\n",
    "    1. [PBMCs from a Healthy Donor: Whole Transcriptome Analysis](https://www.10xgenomics.com/resources/datasets/pbm-cs-from-a-healthy-donor-whole-transcriptome-analysis-3-1-standard-4-0-0): [link to the quant result](https://umd.box.com/shared/static/dk0hmj5mpqjq56afkr5jibavy9e3yil8.tar)\n",
    "    1. [Whole Blood RBC Lysis for PBMCs and Neutrophils, Granulocytes, 3'](https://www.10xgenomics.com/resources/datasets/whole-blood-rbc-lysis-for-pbmcs-neutrophils-granulocytes-3-3-1-standard): [link to the quant result](https://umd.box.com/shared/static/0gnwx7d9hbdmptyi0ddz6mfa79d1l8be.tar)\n",
    "    1. [Peripheral blood mononuclear cells (PBMCs) from a healthy donor - Manual (channel 5)](https://www.10xgenomics.com/resources/datasets/peripheral-blood-mononuclear-cells-pbm-cs-from-a-healthy-donor-manual-channel-5-3-1-standard-3-1-0): [link to the quant result](https://umd.box.com/shared/static/tn884ctombnj214abt8rp77p7kih5i02.tar)\n",
    "    1. [Peripheral blood mononuclear cells (PBMCs) from a healthy donor - Manual (channel 1)](https://www.10xgenomics.com/resources/datasets/peripheral-blood-mononuclear-cells-pbm-cs-from-a-healthy-donor-manual-channel-1-3-1-standard-3-1-0): [link to the quant result](https://umd.box.com/shared/static/0jcgdgy8woj30oarkwhybk8fly7gb7v8.tar)\n",
    "    1. [Peripheral blood mononuclear cells (PBMCs) from a healthy donor - Chromium Connect (channel 5)](https://www.10xgenomics.com/resources/datasets/peripheral-blood-mononuclear-cells-pbm-cs-from-a-healthy-donor-chromium-connect-channel-5-3-1-standard-3-1-0): [link to the quant result](https://umd.box.com/shared/static/kybks0ncf609xhcwvhv7z743zrmvlg94.tar)\n",
    "    1. [Peripheral blood mononuclear cells (PBMCs) from a healthy donor - Chromium Connect (channel 1)](https://www.10xgenomics.com/resources/datasets/peripheral-blood-mononuclear-cells-pbm-cs-from-a-healthy-donor-chromium-connect-channel-1-3-1-standard-3-1-0): [link to the quant result](https://umd.box.com/shared/static/vtuexhbqiyvfob7qdpvsxl1nbqlo074f.tar)\n",
    "    1. [Hodgkin's Lymphoma, Dissociated Tumor: Whole Transcriptome Analysis](https://www.10xgenomics.com/resources/datasets/hodgkins-lymphoma-dissociated-tumor-whole-transcriptome-analysis-3-1-standard-4-0-0): [link to the quant result](https://umd.box.com/shared/static/qis4ovf34wvq12n2uabdiem6w355qry7.tar)\n",
    "    1. [200 Sorted Cells from Human Glioblastoma Multiforme, 3’ LT v3.1](https://www.10xgenomics.com/resources/datasets/200-sorted-cells-from-human-glioblastoma-multiforme-3-lt-v-3-1-3-1-low-6-0-0): [link to the quant result](https://umd.box.com/shared/static/2xf9xf8m1n5vbvmpo1vshwigs7f7o5jd.tar)\n",
    "    1. [750 Sorted Cells from Human Invasive Ductal Carcinoma, 3’ LT v3.1](https://www.10xgenomics.com/resources/datasets/750-sorted-cells-from-human-invasive-ductal-carcinoma-3-lt-v-3-1-3-1-low-6-0-0): [link to the quant result](https://umd.box.com/shared/static/3txnreehxoj2plyypfs6fkibnnbo72h4.tar)\n",
    "    1. [2k Sorted Cells from Human Glioblastoma Multiforme, 3’ v3.1](https://www.10xgenomics.com/resources/datasets/2-k-sorted-cells-from-human-glioblastoma-multiforme-3-v-3-1-3-1-standard-6-0-0): [link to the quant result](https://umd.box.com/shared/static/n0vpgbdwbnnqdw1h9of2ykk7ive9p6pt.tar)\n",
    "    1. [7.5k Sorted Cells from Human Invasive Ductal Carcinoma, 3’ v3.1](https://www.10xgenomics.com/resources/datasets/7-5-k-sorted-cells-from-human-invasive-ductal-carcinoma-3-v-3-1-3-1-standard-6-0-0): [link to the quant result](https://umd.box.com/shared/static/aly78r6bppqf01npbqfopc3epmp17weu.tar)\n",
    "    1. [Human Glioblastoma Multiforme: 3’v3 Whole Transcriptome Analysis](https://www.10xgenomics.com/resources/datasets/human-glioblastoma-multiforme-3-v-3-whole-transcriptome-analysis-3-standard-4-0-0): [link to the quant result](https://umd.box.com/shared/static/suf8pt3avv4rchxfw0bqrshslzieygef.tar)\n",
    "    1. [1k Brain Cells from an E18 Mouse (v3 chemistry)](https://www.10xgenomics.com/resources/datasets/1-k-brain-cells-from-an-e-18-mouse-v-3-chemistry-3-standard-3-0-0): [link to the quant result](https://umd.box.com/shared/static/4w5eiq3qafbru5ocler39j5j28bvgz98.tar)\n",
    "    1. [10k Brain Cells from an E18 Mouse (v3 chemistry)](https://www.10xgenomics.com/resources/datasets/10-k-brain-cells-from-an-e-18-mouse-v-3-chemistry-3-standard-3-0-0): [link to the quant result](https://umd.box.com/shared/static/tym9m73frtp13vo15jhit9uwuk3mtfdq.tar)\n",
    "    1. [1k Heart Cells from an E18 mouse (v3 chemistry)](https://www.10xgenomics.com/resources/datasets/1-k-heart-cells-from-an-e-18-mouse-v-3-chemistry-3-standard-3-0-0): [link to the quant result](https://umd.box.com/shared/static/d838oy3udjvtzjo7tsdiao7u6sazabeg.tar)\n",
    "    1. [10k Heart Cells from an E18 mouse (v3 chemistry)](https://www.10xgenomics.com/resources/datasets/10-k-heart-cells-from-an-e-18-mouse-v-3-chemistry-3-standard-3-0-0): [link to the quant result](https://umd.box.com/shared/static/efinlf6p8weich13kv3bzrlndsx963v4.tar)\n",
    "    1. [10k Mouse E18 Combined Cortex, Hippocampus and Subventricular Zone Cells, Single Indexed](https://www.10xgenomics.com/resources/datasets/10-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-cells-single-indexed-3-1-standard-4-0-0): [link to the quant result](https://umd.box.com/shared/static/mr0yolo83rjdcdqgu6om4q133fpime8r.tar)\n",
    "    1. [10k Mouse E18 Combined Cortex, Hippocampus and Subventricular Zone Cells, Dual Indexed](https://www.10xgenomics.com/resources/datasets/10-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-cells-dual-indexed-3-1-standard-4-0-0): [link to the quant result](https://umd.box.com/shared/static/mr7raea3v5ccn4dchemwhcimpz7t1cwl.tar)\n",
    "    1. [1k PBMCs from a Healthy Donor (v2 chemistry)](https://www.10xgenomics.com/resources/datasets/1-k-pbm-cs-from-a-healthy-donor-v-2-chemistry-3-standard-3-0-0): [link to the quant result](https://umd.box.com/shared/static/xeya5zr0t0wg0t8c20zu0pdhclxywx3c.tar)\n",
    "    1. [1k Brain Cells from an E18 Mouse (v2 chemistry)](https://www.10xgenomics.com/resources/datasets/1-k-brain-cells-from-an-e-18-mouse-v-2-chemistry-3-standard-3-0-0): [link to the quant result](https://umd.box.com/shared/static/a53twm69uo2xf6778asuvw2aft7wkur5.tar)\n",
    "    1. [1k Heart Cells from an E18 mouse (v2 chemistry)](https://www.10xgenomics.com/resources/datasets/1-k-heart-cells-from-an-e-18-mouse-v-2-chemistry-3-standard-3-0-0): [link to the quant result](https://umd.box.com/shared/static/p4ieuzimfgrjfsr9rzhrn48kved4ha7m.tar)\n",
    "\n",
    "    To obtain the information of the available datasets as \n",
    "    a dataframe, one can run `preprocessed_10x_data()`\n",
    "    \"\"\"\n",
    "    \n",
    "    import pandas as pd\n",
    "    import os\n",
    "    import shutil\n",
    "    import urllib.request \n",
    "    import tarfile\n",
    "\n",
    "    say(quiet, \"Processing parameters\")\n",
    "    # load available dataset sheet\n",
    "    # location = os.path.dirname(os.path.realpath(__file__))\n",
    "    # my_file = os.path.join(location, 'data', 'available_datasets.tsv')\n",
    "    my_file = os.path.join('data', 'available_datasets.tsv')\n",
    "    available_datasets = pd.read_csv(my_file, sep=\"\\t\")\n",
    "\n",
    "    nd = len(dataset_ids)\n",
    "    # if no dataset is provided, just return the available dataset dataframe\n",
    "    if nd == 0:\n",
    "        return available_datasets\n",
    "\n",
    "    # check whether output_format are valid\n",
    "    # we just check the length, the validity of\n",
    "    # each outputFormat will be checked by load_fry\n",
    "    if type(list(output_format)) is dict:\n",
    "        # if a dictionary is given,\n",
    "        # it should be either one customized format\n",
    "        # or the format of each fetched datasets\n",
    "        # so check the name \n",
    "        if list(output_format.keys()).sort() != dataset_ids.sort():\n",
    "            # now it should be one customized format\n",
    "            output_format = dict(zip(dataset_ids, [output_format]*nd))\n",
    "        # otherwise, each dataset should get a format, so do nothing\n",
    "    elif (type(output_format) is str):\n",
    "        # if a str is given, it should be a pre-defined format\n",
    "        # and it will be used for all datasets\n",
    "        output_format = dict(zip(dataset_ids, [output_format]*nd))\n",
    "\n",
    "\n",
    "    if type(nonzero) is bool:\n",
    "        nonzero = dict(zip(dataset_ids, [nonzero]*nd))\n",
    "\n",
    "    dataset_paths = fetch_processed_quant(dataset_ids = dataset_ids,\n",
    "                                        fetch_dir = fetch_dir,\n",
    "                                        force = force,\n",
    "                                        delete_tar = delete_tar,\n",
    "                                        quiet = quiet)\n",
    "    ann_list = {}\n",
    "    for dataset_id in dataset_ids:\n",
    "        nonzero_ds = nonzero[dataset_id]\n",
    "        output_format_ds = output_format[dataset_id]\n",
    "        dataset_path_ds = dataset_paths[dataset_id]\n",
    "        say(quiet, f\"Loading dataset {dataset_id}\")\n",
    "        ann_list[dataset_id] = load_fry(frydir = dataset_path_ds,\n",
    "                                        output_format = output_format_ds,\n",
    "                                        nonzero = nonzero_ds,\n",
    "                                        quiet = quiet)\n",
    "\n",
    "    return ann_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad27a99-2176-4554-b150-2f2e36285d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0f8bed1-651d-4fcc-a96a-90dfe12be834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing parameters\n",
      "Processing dataset #1\n",
      "  - output dir exists:\n",
      "    10x_datasets/5f080c6082f11ea9fc6448482e6fb590\n",
      "  - use the existing quant result\n",
      "Processing dataset #2\n",
      "  - output dir exists:\n",
      "    10x_datasets/5b36a7bfda36a7093adc8e30c3fa92c8\n",
      "  - use the existing quant result\n",
      "Processing dataset #3\n",
      "  - output dir exists:\n",
      "    10x_datasets/265ebe8f77ad90db350984d9c7a59e52\n",
      "  - use the existing quant result\n",
      "Removing downloaded tar files\n",
      "Done\n",
      "Loading dataset 1\n",
      "Loading dataset 2\n",
      "Loading dataset 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: AnnData object with n_obs × n_vars = 10620 × 36601\n",
       "     obs: 'barcodes',\n",
       " 2: AnnData object with n_obs × n_vars = 10795 × 36601\n",
       "     obs: 'barcodes',\n",
       " 3: AnnData object with n_obs × n_vars = 76122 × 36601\n",
       "     obs: 'barcodes'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_processed_quant([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678bcc3a-6ce5-481f-9c4d-cffda1f62d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e3d4e6a5-f38f-4de6-935f-976346b3c0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--quiet'], dest='quiet', nargs=0, const=True, default=False, type=None, choices=None, help='A flag indicates whether help messaged should not be printed.', metavar=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# from pyroe import make_splici_txome\n",
    "# from pyroe import fetch_processed_quant\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "# Create the parser\n",
    "parser = argparse.ArgumentParser(description='The pyroe package provides useful functions for preparing input files required by alevin-fry.',\n",
    "                                    prog='pyroe')\n",
    "subparsers = parser.add_subparsers(title='subcommands', dest='command',\n",
    "                                    description='valid subcommands',\n",
    "                                    help='additional help')\n",
    "parser_makeSplici = subparsers.add_parser('make-splici', help='Make splici reference')\n",
    "parser_makeSplici.add_argument('genome_path', metavar='genome-path', type=str, help='The path to a genome fasta file.')\n",
    "parser_makeSplici.add_argument('gtf_path', metavar='gtf-path', type=str, help='The path to a gtf file.')\n",
    "parser_makeSplici.add_argument('read_length', metavar='read-length', type=int, help='The read length of the single-cell experiment being processed (determines flank size).')\n",
    "parser_makeSplici.add_argument('output_dir', metavar='output-dir', type=str, help='The output directory where splici reference files will be written.')\n",
    "parser_makeSplici.add_argument('--filename-prefix', type=str, default=\"splici\", help='The file name prefix of the generated output files.')\n",
    "parser_makeSplici.add_argument('--flank-trim-length', type=int, default=5, help='Determines the amount subtracted from the read length to get the flank length.')\n",
    "parser_makeSplici.add_argument('--extra-spliced', type=str, help='The path to an extra spliced sequence fasta file.')\n",
    "parser_makeSplici.add_argument('--extra-unspliced', type=str, help='The path to an extra unspliced sequence fasta file.')\n",
    "parser_makeSplici.add_argument('--bt-path', type=str, default=\"bedtools\", help='The path to bedtools v2.30.0 or greater.')\n",
    "parser_makeSplici.add_argument('--no-bt', action='store_true', help='A flag indicates whether bedtools will be used for generating splici reference files.')\n",
    "parser_makeSplici.add_argument('--dedup-seqs', action='store_true', help='A flag indicates whether identical sequences will be deduplicated.')\n",
    "parser_makeSplici.add_argument('--no-flanking-merge', action='store_true', help='A flag indicates whether flank lengths will be considered when merging introns.')\n",
    "\n",
    "parser_fetchQuant = subparsers.add_parser('fetch-quant', help='Fetch processed quant results')\n",
    "parser_fetchQuant.add_argument('dataset_ids', metavar='dataset-ids', nargs='+', type=int, help='The ids of the datasets to fetch')\n",
    "parser_fetchQuant.add_argument('--fetch_dir', type=str, default=\"processed_quant\",  help='The path to a directory for storing fetched datasets.')\n",
    "parser_fetchQuant.add_argument('--force', action='store_false', help='A flag indicates whether existing datasets will be redownloaded by force.')\n",
    "parser_fetchQuant.add_argument('--delete_tar', action='store_true', help='A flag indicates whether fetched tar files will be deleted.')\n",
    "parser_fetchQuant.add_argument('--quiet', action='store_true', help='A flag indicates whether help messaged should not be printed.')\n",
    "\n",
    "# # Execute the parse_args() method\n",
    "# args = parser.parse_args()\n",
    "# if args.command == 'make-splici':\n",
    "#     make_splici_txome.make_splici_txome(\n",
    "#     genome_path=args.genome_path,\n",
    "#     gtf_path=args.gtf_path,\n",
    "#     read_length=args.read_length,\n",
    "#     output_dir=args.output_dir,\n",
    "#     flank_trim_length=args.flank_trim_length,\n",
    "#     filename_prefix=args.filename_prefix,\n",
    "#     extra_spliced=args.extra_spliced,\n",
    "#     extra_unspliced=args.extra_unspliced,\n",
    "#     dedup_seqs=args.dedup_seqs,\n",
    "#     no_bt=args.no_bt,\n",
    "#     bt_path=args.bt_path,\n",
    "#     no_flanking_merge=args.no_flanking_merge)\n",
    "# elif args.command == 'fetch-quant':\n",
    "#     print(\"Ok\")\n",
    "\n",
    "\n",
    "# else:\n",
    "#     print(parser.print_help())\n",
    "#     sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "affb46df-b2f9-4827-b075-589f23672de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: pyroe [-h] {make-splici,fetch-quant} ...\n",
      "\n",
      "The pyroe package provides useful functions for preparing input files required\n",
      "by alevin-fry.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "\n",
      "subcommands:\n",
      "  valid subcommands\n",
      "\n",
      "  {make-splici,fetch-quant}\n",
      "                        additional help\n",
      "    make-splici         Make splici reference\n",
      "    fetch-quant         Fetch processed quant results\n"
     ]
    }
   ],
   "source": [
    "parser.print_help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5231f317-d79c-46aa-aced-9653f3b61d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = parser.parse_args([\"fetch-quant\", '1', '2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8095c49-d899-4b96-910d-59d107923f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_datasets = fetch_processed_quant()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
